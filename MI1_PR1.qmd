---
title: Dirección interna de corrección en grandes modelos de lenguaje (LLMs)
author: Iván Moreno (imorenocencerrado@alumnos.viu.es)
lang: es
format:
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
---

## Introducción

Los grandes modelos de lenguaje (Large Language Models, o LLMs) han demostrando una notable capacidad para generar respuestas coherentes y contextualmente relevantes en una amplia gama de tareas.

Sin embargo, su elevado número de parámetros implica un alto coste computacional, especialmente en aplicaciones de sistemas de pregunta-respuesta (QA), donde se desconoce la calidad (i.e., corrección) de la respuesta hasta el momento de su generación

Esto plantea la interrogante de si dichos modelos poseen una “dirección interna de conocimiento o habilidad” que les permita, a partir de sus activaciones neuronales, determinar de forma implícita si están capacitados para proporcionar respuestas correctas.

Comprender este mecanismo no solo enriquecería el conocimiento teórico acerca de las representaciones internas de estos modelos, sino que también abriría nuevas vías para optimizar su uso en aplicaciones prácticas, mejorando la eficiencia y fiabilidad de los sistemas QA.


## Pregunta de investigación

¿Existen subespacios en las activaciones neuronales de un LLM que permitan predecir, previo a su generación, si una pregunta recibirá una respuesta factualmente correcta o incorrecta?


## Formulación de hipótesis

A continuación, formulamos tres hipótesis: de primer nivel (constatación), segundo nivel (relación causal) y tercer nivel (asociación)[^1].

[^1]: HEINZ DIETERICH. 2021. Nueva Guia para la Investigacion Cientifica, S.l.: Grupo Editor Orfila Valentini, S.A. 

### Hipótesis de constatación

Existe una señal detectable en las activaciones internas de un modelo de lenguaje que está directamente relacionada con la corrección de las respuestas generadas.

### Hipótesis de relación causal

La supresión de la señal identificada en el subespacio de activaciones internas afecta de manera negativa la calidad de las respuestas generadas.

### Hipótesis de asociación

La señal identificada permite discernir aquellos casos en los que el modelo no debería ser utilizado para generar respuestas, mejorando así la eficiencia y fiabilidad de los sistemas QA.


## Diseño experimental

### Enfoque metodológico
El estudio se enmarca dentro de un enfoque cuantitativo, combinando la generación de hipótesis a partir de datos empíricos y el análisis estadístico para evaluar la significancia de los resultados.

### Procedimiento

1. **Recopilación de datos:** Se forma un conjunto de evaluación compuesto por pares de preguntas y respuestas, extraídos de diversas fuentes, y categorizados (de respuesta abierta, utilizando razonamiento explícito, de múltiples respuestas, por dominio o temática...).
2. **Generación de respuestas:** Se empleará un modelo de lenguaje preentrenado para generar respuestas a las preguntas del conjunto recopilado.
3. **Evaluación de corrección:** Las respuestas generadas serán cotejadas con las respuestas esperadas, asignando así una etiqueta binaria de “correcta” o “incorrecta” a cada respuesta.
4. **Captura de activaciones internas:** Durante el procesamiento de las preguntas, se capturarán las activaciones de las capas internas del modelo que se consideren relevantes para la generación de respuestas.
5. **Entrenamiento del clasificador:** Utilizando las activaciones internas como variables independientes y las etiquetas de corrección como variable dependiente, se entrenará un clasificador lineal binario. Se emplea una asignación aleatoria de datos en conjuntos de entrenamiento y prueba para asegurar la validez interna del experimento.
6. **Evaluación del clasificador:** Se medirá el desempeño del clasificador en el conjunto de pruebas mediante métricas estándar (precisión, recall, F1-score, y área bajo la curva ROC). Se analizará si el clasificador es capaz de separar significativamente las respuestas correctas de las incorrectas.

## Resultados esperados

Se espera que el clasificador logre identificar de manera consistente si la respuesta generada por el modelo es correcta o incorrecta, basándose únicamente en las activaciones internas del modelo. Esto sugeriría la existencia de un subespacio de activaciones que codifica información relevante sobre la corrección de las respuestas, respaldando así la hipótesis de constatación.
