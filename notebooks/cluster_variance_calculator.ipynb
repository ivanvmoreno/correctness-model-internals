{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to Python path\n",
    "src_path = str(Path(\"./\").resolve().parent)\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "sys.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from src.utils.data import load_activations, load_labels, get_experiment_activations_configs_df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    match = re.search(r'\\d+', filename)\n",
    "    return int(match.group()) if match else -1\n",
    "\n",
    "def intra_class_variance_over_inter_class_variance(vectors, labels):\n",
    "    vectors = vectors.numpy()\n",
    "    class_0_vectors = vectors[labels == 0]\n",
    "    class_1_vectors = vectors[labels == 1]\n",
    "    class_0_mean = np.mean(class_0_vectors, axis=0)\n",
    "    class_1_mean = np.mean(class_1_vectors, axis=0)\n",
    "    class_0_variance = np.mean(np.linalg.norm(class_0_vectors - class_0_mean, axis=1))\n",
    "    class_1_variance = np.mean(np.linalg.norm(class_1_vectors - class_1_mean, axis=1))\n",
    "    total_mean = np.mean(vectors, axis=0)\n",
    "    # return between-class variance over within-class variance\n",
    "    return (np.linalg.norm(class_0_mean - total_mean) + np.linalg.norm(class_1_mean - total_mean)) / (class_0_variance + class_1_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"mistral_7b_instruct\",\n",
    "    \"ministral_8b_instruct\",\n",
    "    \"qwen_2.5_7b_instruct\",\n",
    "    \"llama3.1_8b_chat\",\n",
    "    \"llama3.3_70b\",\n",
    "    \"deepseek_qwen_32b\",\n",
    "]\n",
    "\n",
    "datasets = [\n",
    "    \"gsm8k\",\n",
    "    \"trivia_qa_2_60k\",\n",
    "    \"birth_years_4k\",\n",
    "    \"cities_10k\",\n",
    "    \"medals_9k\",\n",
    "    \"math_operations_6k\"\n",
    "]\n",
    "\n",
    "BASE_PATH = {}\n",
    "BASE_PATH[\"llama3.1_8b_chat\"] = \"/runpod-volume/anton/correctness-model-internals/data_for_classification\"\n",
    "BASE_PATH[\"llama3.3_70b\"] = \"/runpod-volume/arnau/correctness-model-internals/data_for_classification\"\n",
    "BASE_PATH[\"deepseek_qwen_32b\"] = \"/runpod-volume/arnau/correctness-model-internals/data_for_classification\"\n",
    "BASE_PATH[\"mistral_7b_instruct\"] = \"/runpod-volume/anton/correctness-model-internals/data_for_classification\"\n",
    "BASE_PATH[\"ministral_8b_instruct\"] = \"/runpod-volume/arnau/correctness-model-internals/data_for_classification\"\n",
    "BASE_PATH[\"qwen_2.5_7b_instruct\"] = \"/runpod-volume/arnau/correctness-model-internals/data_for_classification\"\n",
    "\n",
    "layers = {}\n",
    "layers[\"llama3.1_8b_chat\"] = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n",
    "layers[\"llama3.3_70b\"] = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76]\n",
    "layers[\"deepseek_qwen_32b\"] = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60]\n",
    "layers[\"mistral_7b_instruct\"] = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n",
    "layers[\"ministral_8b_instruct\"] = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34]\n",
    "layers[\"qwen_2.5_7b_instruct\"] = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for model_id in models:\n",
    "    for dataset_id in datasets:\n",
    "        prompt_id = \"base\"\n",
    "        if dataset_id == \"gsm8k\":\n",
    "            prompt_id = \"base_3_shot\"\n",
    "        subset_id = \"main\"\n",
    "        input_type = \"prompt_only\"\n",
    "        layers_model = layers[model_id]\n",
    "        BASE_PATH_MODEL = BASE_PATH[model_id]\n",
    "        vars = []\n",
    "        for layer in layers_model:\n",
    "            activations, indices = load_activations(\n",
    "                base_path=BASE_PATH_MODEL,\n",
    "                model_id=model_id,\n",
    "                dataset_id=dataset_id,\n",
    "                prompt_id=prompt_id,\n",
    "                subset_id=subset_id,\n",
    "                input_type=input_type,\n",
    "                layer=layer,\n",
    "            )\n",
    "            labels_df = load_labels(\n",
    "                base_path=BASE_PATH_MODEL,\n",
    "                model_id=model_id,\n",
    "                dataset_id=dataset_id,\n",
    "                prompt_id=prompt_id,\n",
    "                subset_id=subset_id,\n",
    "            )\n",
    "            labels = labels_df['correct']\n",
    "            activations, labels\n",
    "            var = intra_class_variance_over_inter_class_variance(activations, labels)\n",
    "            vars.append(var)\n",
    "\n",
    "        print(model_id, dataset_id, vars)\n",
    "        results.append({\n",
    "            \"model\": model_id,\n",
    "            \"dataset\": dataset_id,\n",
    "            \"aucs\": vars\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"intra_class_variance_over_inter_class_variance_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
